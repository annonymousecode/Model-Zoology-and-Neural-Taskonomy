{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Option Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import pandas as pd\n",
    "import os, sys, torch\n",
    "sys.path.append('..')\n",
    "\n",
    "model_types = ['imagenet', 'segmentation', 'detection', 'video']\n",
    "pytorch_dirs = dict(zip(model_types, ['.', '.segmentation.', '.detection.', '.video.']))\n",
    "\n",
    "model_archs = {\n",
    "    'imagenet': ['alexnet','vgg11','vgg13','vgg16','vgg19','vgg11_bn','vgg13_bn','vgg16_bn','vgg19_bn',\n",
    "                        'resnet18','resnet34','resnet50','resnet101','resnet152',\n",
    "                        'squeezenet1_0','squeezenet1_1',\n",
    "                        'densenet121','densenet161','densenet169','densenet201',\n",
    "                        'googlenet', 'inception_v3',\n",
    "                        'shufflenet_v2_x0_5', 'shufflenet_v2_x1_0', 'mobilenet_v2',\n",
    "                        'resnext50_32x4d','resnext101_32x8d','wide_resnet50_2','wide_resnet101_2',\n",
    "                        'mnasnet0_5','mnasnet1_0',],\n",
    "    'segmentation': ['fasterrcnn_resnet50_fpn', 'maskrcnn_resnet50_fpn', 'keypointrcnn_resnet50_fpn'],\n",
    "    'detection': ['deeplabv3_resnet101', 'fcn_resnet101'],\n",
    "    'video': ['r3d_18', 'r2plus1d_18','mc3_18'],\n",
    "}\n",
    "\n",
    "taskonomy_optiomns = {}\n",
    "for model_type in model_types:\n",
    "    model_options[model_type] = {}\n",
    "    \n",
    "training_calls = {'random': '(pretrained=False)', 'pretrained': '(pretrained=True)'}\n",
    "    \n",
    "for model_type, model_list in model_archs.items():\n",
    "    for model in model_list:\n",
    "        for training_type in ['random', 'pretrained']:\n",
    "            model_string = '_'.join([model, training_type])\n",
    "            model_call = 'models' + pytorch_dirs[model_type] + model + training_calls[training_type]\n",
    "            model_options[model_type][model_string] = model_call\n",
    "            \n",
    "custom_model_options = {\n",
    "    'alexnet_norelu_random': 'AlexNet_NoRelu()',\n",
    "    'alexnet_nomaxpool_random': 'AlexNet_NoMaxPool()',\n",
    "    'alexnet_norelu_nomaxpool_random': 'AlexNet_NoRelu_NoMaxPool()',\n",
    "    'alexnet_nuconvolve_random': 'AlexNet_NuConvolve()',\n",
    "}\n",
    "\n",
    "model_options['custom'] = custom_model_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../toolbox')\n",
    "import torchvision.transforms as transforms\n",
    "import video_transforms as video_transforms\n",
    "\n",
    "model_transforms = {\n",
    "    'imagenet': transforms.Compose([\n",
    "        transforms.Resize((224,224)), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "    'segmentation': transforms.Compose([\n",
    "        transforms.Resize((224,224)), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "    'detection': transforms.Compose([\n",
    "        transforms.Resize((224,224)), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "    'video': transforms.Compose([\n",
    "        video_transforms.ToFloatTensorInZeroOne(),\n",
    "        video_transforms.Resize((224,224)),\n",
    "        video_transforms.Normalize(mean=[0.43216, 0.394666, 0.37645],\n",
    "                                   std=[0.22803, 0.22145, 0.216989]),\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = {\n",
    "    'alexnet': 'AlexNet',\n",
    "    'vgg11': 'VGG11',\n",
    "    'vgg13': 'VGG13',\n",
    "    'vgg16': 'VGG16',\n",
    "    'vgg19': 'VGG19',\n",
    "    'vgg11_bn': 'VGG11-BatchNorm',\n",
    "    'vgg13_bn': 'VGG13-BatchNorm',\n",
    "    'vgg16_bn': 'VGG16-BatchNorm',\n",
    "    'vgg19_bn': 'VGG19-BatchNorm',\n",
    "    'resnet18': 'ResNet18',\n",
    "    'resnet34': 'ResNet34',\n",
    "    'resnet50': 'ResNet50',\n",
    "    'resnet101': 'ResNet101',\n",
    "    'resnet152': 'ResNet152',\n",
    "    'squeezenet1_0': 'SqueezeNet1.0',\n",
    "    'squeezenet1_1': 'SqueezeNet1.1',\n",
    "    'densenet121': 'DenseNet121',\n",
    "    'densenet161': 'DenseNet161',\n",
    "    'densenet169': 'DenseNet169',\n",
    "    'densenet201': 'DenseNet201',\n",
    "    'googlenet': 'GoogleNet',\n",
    "    'shufflenet_v2_x0_5': 'ShuffleNet-V2-x0.5',\n",
    "    'shufflenet_v2_x1_0': 'ShuffleNet-V2-x1.0',\n",
    "    'mobilenet_v2': 'MobileNet-V2',\n",
    "    'resnext50_32x4d': 'ResNext50-32x4D',\n",
    "    'resnext101_32x8d': 'ResNext50-32x8D',\n",
    "    'wide_resnet50_2': 'Wide-ResNet50',\n",
    "    'wide_resnet101_2': 'Wide-ResNet101',\n",
    "    'mnasnet0_5': 'MNASNet0.5',\n",
    "    'mnasnet1_0': 'MNASNet1.0',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{k:v for k,v in model_options['detection'].items() \n",
    " if any(s in k for s in model_names['imagenet'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import compress\n",
    "list(compress(model_types, [('alexnet' in model_options[key]) for key in list(model_options.keys())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info = pd.read_csv('model_information.csv')\n",
    "pytorch_dirs['inception'] = '.'\n",
    "model_options = {}\n",
    "\n",
    "for index, row in model_info.iterrows():\n",
    "    model = row['model_arch']\n",
    "    model_type = row['model_type']\n",
    "    for training_type in ['random', 'pretrained']:\n",
    "        model_string = '_'.join([model, training_type])\n",
    "        model_call = 'models' + pytorch_dirs[model_type] + model + training_calls[training_type]\n",
    "        model_options[model_string] = ({'arch': model, 'type': model_type, 'call': model_call})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[model_string for model_string in list(model_options.keys()) if model_options[model_string]['type'] == 'imagenet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bash Scripting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os, stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('compute_model_rdms.sh', 'w') as rsh:\n",
    "    rsh.write('#! /bin/bash\\n')\n",
    "    for index, model_string in enumerate(model_options.keys()):\n",
    "        if index < len(model_options.keys()) - 1:\n",
    "            rsh.write(\"python compute_model_rdms.py --model_string='{}' & \\n\".format(model_string))\n",
    "            rsh.write('wait; \\n')\n",
    "        if index + 1 == len(model_options.keys()):\n",
    "            rsh.write(\"python compute_model_rdms.py --model_string='{}'\".format(model_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('compute_model_rdms.sh', 'w') as rsh:\n",
    "    rsh.write('#! /bin/bash\\n')\n",
    "    for index, model_string in enumerate(model_options.keys()):\n",
    "        if index < len(model_options.keys()) - 1:\n",
    "            rsh.write(\"python compute_other_model_rdms.py --model_string='{}' & \\n\".format(model_string))\n",
    "            rsh.write('wait; \\n')\n",
    "        if index + 1 == len(model_options.keys()):\n",
    "            rsh.write(\"python compute_other_model_rdms.py --model_string='{}'\".format(model_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mouse_model_rsa.sh', 'w') as rsh:\n",
    "    rsh.write('#! /bin/bash\\n')\n",
    "    for index, model_string in enumerate(model_options.keys()):\n",
    "        if index < len(model_options.keys()) - 1:\n",
    "            rsh.write(\"python mouse_model_rsa.py --model_string='{}' & \\n\".format(model_string))\n",
    "            rsh.write('wait; \\n')\n",
    "        if index + 1 == len(model_options.keys()):\n",
    "            rsh.write(\"python mouse_model_rsa.py --model_string='{}'\".format(model_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# devices = [0,1,2]\n",
    "# ppd = [len(array) for array in np.array_split(range(condition_count), len(devices))]\n",
    "# for device in devices:\n",
    "#     with open('train_device_{}.sh'.format(device), 'w') as rsh:\n",
    "#         rsh.write('#! /bin/bash\\n')\n",
    "#         for i in range(ppd[device]):\n",
    "#             rsh.write('python continue_classifier_training.py --device={} & \\n'.format(device))\n",
    "#             if i < ppd[device] - 1:\n",
    "#                 rsh.write('wait; \\n')\n",
    "#             if i == ppd[device] - 1:\n",
    "#                 rsh.write('wait')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Option Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visual_priors import taskonomy_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_typology = pd.read_csv('task_typology.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_taskonomy_model(model_name):\n",
    "    weights = torch.load('task_weights/{}_encoder.pth'.format(model_name))\n",
    "    print('{} weights loaded succesfully.'.format(model_name))\n",
    "    model = taskonomy_network.TaskonomyEncoder()\n",
    "    model.load_state_dict(weights['state_dict'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_taskonomy_options():\n",
    "    taskonomy_options = {}\n",
    "\n",
    "    for index, row in task_typology.iterrows():\n",
    "        model_name = row['model']\n",
    "        model_type = 'taskonomy'\n",
    "        train_type = 'taskonomy'\n",
    "        model_string = model_name\n",
    "        model_call = \"instantiate_taskonomy_model('{}')\".format(model_name)\n",
    "        taskonomy_options[model_string] = ({'model_name': model_name, 'model_type': model_type, \n",
    "                                        'train_type': train_type, 'call': model_call})\n",
    "        \n",
    "    taskonomy_options['taskonomy_random'] = ({'model_name': 'taskonomy_random', 'model_type': model_type,\n",
    "                                             'train_type': 'random', 'call': 'taskonomy_network.TaskonomyEncoder()'})\n",
    "            \n",
    "    return taskonomy_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taskonomy_options = define_taskonomy_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taskonomy_options['autoencoding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taskonomy_options['taskonomy_random']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = eval(taskonomy_options['autoencoding']['call'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = eval(taskonomy_options['class_object']['call'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(model_1, model_2):\n",
    "    models_differ = 0\n",
    "    for key_item_1, key_item_2 in zip(model_1.state_dict().items(), model_2.state_dict().items()):\n",
    "        if torch.equal(key_item_1[1], key_item_2[1]):\n",
    "            pass\n",
    "        else:\n",
    "            models_differ += 1\n",
    "            if (key_item_1[0] == key_item_2[0]):\n",
    "                #print('Mismtach found at', key_item_1[0])\n",
    "                continue\n",
    "            else:\n",
    "                raise Exception\n",
    "    if models_differ == 0:\n",
    "        print('Models match.')\n",
    "    if models_differ != 0:\n",
    "        print('Models differ.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_models(model1, model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_options import get_model_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['autoencoding', 'class_object', 'class_scene', 'curvature', 'colorization', 'denoising', 'depth_euclidean', 'depth_zbuffer', 'edge_occlusion', 'edge_texture', 'egomotion', 'fixated_pose', 'inpainting', 'jigsaw', 'keypoints2d', 'keypoints3d', 'nonfixated_pose', 'normal', 'point_matching', 'reshading', 'room_layout', 'segment_semantic', 'segment_unsup25d', 'segment_unsup2d', 'vanishing_point'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model_options(train_type='taskonomy').keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
