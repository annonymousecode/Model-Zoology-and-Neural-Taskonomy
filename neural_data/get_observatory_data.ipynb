{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allensdk.core.brain_observatory_cache import BrainObservatoryCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/storage/abarbu/allen-brain-observatory/visual-coding-2p/'\n",
    "MANIFEST_FILE = os.path.join(DATA_DIR, 'manifest.json')\n",
    "boc = BrainObservatoryCache(manifest_file=MANIFEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BAD_CONTAINER_IDS = [511510998, 511510681, 517328083, 527676429, 527550471, 530243910, 570278595, 571039045, \n",
    "                     585905043, 587695553, 596780703, 598134911, 599587151, 605113106]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = boc.get_ophys_experiments(session_types=['three_session_B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(experiments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes on Dataset Structure\n",
    "* 119 Images (118 Natural Scenes; 1 Gray Screen)\n",
    "* 5950 Trials (50 Trials Per Image)\n",
    "* 6 Visual Areas\n",
    "* 12 Cre Lines\n",
    "* ~ 4/5 Cortical Layers, approximated by Imaging Depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brain Observatory Responses by Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing Procedural Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = deepcopy(next(iter(experiments)))\n",
    "experiment_id = experiment.pop('id')\n",
    "experiment['experiment_id'] = experiment_id\n",
    "\n",
    "events = boc.get_ophys_experiment_events(experiment_id)\n",
    "data = boc.get_ophys_experiment_data(experiment_id)\n",
    "stim_table = data.get_stimulus_table('natural_scenes')\n",
    "frames = np.unique(stim_table.frame)\n",
    "\n",
    "experiment_metadata = data.get_metadata()\n",
    "cell_specimens = data.get_cell_specimen_ids()\n",
    "\n",
    "metadata_dict = {}\n",
    "for cell_specimen_index, cell_specimen_id in enumerate(cell_specimens):\n",
    "        metadata_dict[cell_specimen_id] = {**experiment, **experiment_metadata}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_dict[next(iter(metadata_dict))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_dict = {}\n",
    "\n",
    "all_trials = False\n",
    "\n",
    "if not all_trials: \n",
    "    response = np.zeros((len(frames), events.shape[0]))\n",
    "\n",
    "for frame in frames:\n",
    "    frame_table = stim_table[stim_table.frame==frame]\n",
    "    trials = np.array([np.sum(events[:,row.start:row.end], axis=1) for i, row in frame_table.iterrows()])\n",
    "    \n",
    "    if not all_trials:\n",
    "        response[frame] = np.mean(trials, axis=0)  \n",
    "\n",
    "if not all_trials:\n",
    "    for cell_specimen_index, cell_specimen_id in enumerate(cell_specimens):\n",
    "        response_dict[cell_specimen_id] = response[:,cell_specimen_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.shape, response_dict[next(iter(response_dict))].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_saver_dir = 'response_arrays/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_data_from_experiments(all_trials=False, return_metadata=False):\n",
    "    experiments = boc.get_ophys_experiments(session_types=['three_session_B'])\n",
    "        \n",
    "    response_dict = {}\n",
    "    metadata_dict = {}\n",
    "    with tqdm(experiments) as pbar:\n",
    "        for experiment in experiments:\n",
    "            if experiment['experiment_container_id'] in BAD_CONTAINER_IDS:\n",
    "                continue\n",
    "            experiment_id = experiment.pop('id')\n",
    "            experiment['experiment_id'] = experiment_id\n",
    "            pbar.set_description(\"Processing Experiment {}; {} Trials\"\n",
    "                                 .format(experiment_id, 'Averaging' if not all_trials else 'Appending All'))\n",
    "            \n",
    "\n",
    "            events = boc.get_ophys_experiment_events(experiment_id)\n",
    "            data = boc.get_ophys_experiment_data(experiment_id)\n",
    "            stim_table = data.get_stimulus_table('natural_scenes')\n",
    "            frames = np.unique(stim_table.frame)\n",
    "            \n",
    "            experiment_metadata = data.get_metadata()\n",
    "            cell_specimens = data.get_cell_specimen_ids()\n",
    "\n",
    "            if all_trials:\n",
    "                response_temp_list = []\n",
    "            if not all_trials: \n",
    "                response = np.zeros((len(frames), events.shape[0]))\n",
    "\n",
    "            for frame in frames:\n",
    "                frame_table = stim_table[stim_table.frame==frame]\n",
    "                trials = np.array([np.sum(events[:,row.start:row.end], axis=1) for i, row in frame_table.iterrows()])\n",
    "\n",
    "                if all_trials:\n",
    "                    response_temp_list.append(trials)\n",
    "                if not all_trials:\n",
    "                    response[frame] = np.mean(trials, axis=0)  \n",
    "\n",
    "            if all_trials:\n",
    "                frames_sort_index = np.argsort(frames)\n",
    "\n",
    "                response = [response_temp_list[i] for i in frames_sort_index]\n",
    "                trials = [frames[i]*np.ones(response_temp_list[frames[i]].shape[0]) for i in frames_sort_index]\n",
    "\n",
    "                # put grey screen (frame == -1) at the end of the array, should be sorted to first\n",
    "                grey = response.pop(0)\n",
    "                response.append(grey)  \n",
    "\n",
    "                grey_trial = trials.pop(0)\n",
    "                trials.append(grey_trial)\n",
    "                trials = np.hstack(trials)\n",
    "                response = np.vstack(response)  # [stim_table.shape[0], events.shape[0]]\n",
    "\n",
    "            for cell_specimen_index, cell_specimen_id in enumerate(cell_specimens):\n",
    "                response_dict[cell_specimen_id] = response[:,cell_specimen_index]\n",
    "                metadata_dict[cell_specimen_id] = {**experiment, **experiment_metadata}\n",
    "            \n",
    "            pbar.update(1)\n",
    "\n",
    "    return response_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = os.path.join(output_dir, data_saver_dir, 'response_bytrial_bycell.pkl')\n",
    "if os.path.exists(output_file):\n",
    "    response_dict_bytrial = pickle.load(open(output_file, 'rb'))\n",
    "\n",
    "if not os.path.exists(output_file):\n",
    "    response_dict_bytrial = get_response_data_from_experiments(all_trials=True)\n",
    "    \n",
    "    with open(output_file, 'wb') as file:\n",
    "        pickle.dump(response_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = os.path.join(output_dir, data_saver_dir, 'response_average_bycell.pkl')\n",
    "if os.path.exists(output_file):\n",
    "    response_dict_avg = pickle.load(open(output_file, 'rb'))\n",
    "\n",
    "if not os.path.exists(output_file):\n",
    "    response_dict_avg = get_response_data_from_experiments(all_trials=False)\n",
    "    \n",
    "    with open(output_file, 'wb') as file:\n",
    "        pickle.dump(response_dict_avg, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = os.path.join(output_dir, 'cell_response_average.pkl')\n",
    "if not os.path.exists(output_file):\n",
    "    with open(output_file, 'wb') as file:\n",
    "        pickle.dump(response_dict_avg, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cell_metadata_from_experiments():\n",
    "    experiments = boc.get_ophys_experiments(session_types=['three_session_B'])\n",
    "        \n",
    "    metadata_dict = {}\n",
    "    with tqdm(experiments) as pbar:\n",
    "        for experiment in experiments:\n",
    "            if experiment['experiment_container_id'] in BAD_CONTAINER_IDS:\n",
    "                continue\n",
    "            experiment_id = experiment.pop('id')\n",
    "            experiment['experiment_id'] = experiment_id \n",
    "\n",
    "            data = boc.get_ophys_experiment_data(experiment_id)\n",
    "            experiment_metadata = data.get_metadata()\n",
    "            cell_specimens = data.get_cell_specimen_ids()\n",
    "\n",
    "            for cell_specimen_index, cell_specimen_id in enumerate(cell_specimens):\n",
    "                metadata_dict[cell_specimen_id] = {**experiment, **experiment_metadata}\n",
    "            \n",
    "            pbar.update(1)\n",
    "\n",
    "    return metadata_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = os.path.join(output_dir, 'experiment_data.pkl')\n",
    "if os.path.exists(output_file):\n",
    "    metadata_dict = pickle.load(open(output_file, 'rb'))\n",
    "\n",
    "if not os.path.exists(output_file):\n",
    "    metadata_dict = get_cell_metadata_from_experiments()\n",
    "    \n",
    "    with open(output_file, 'wb') as file:\n",
    "        pickle.dump(metadata_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell_specimens is a database that contains many useful pre-computed metrics, aggregated by the Allen Institute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_specimen_data = pd.DataFrame(boc.get_cell_specimens())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_dictlist = []\n",
    "for cell_id in metadata_dict:\n",
    "    metadata_dict[cell_id]['cell_specimen_id'] = cell_id\n",
    "    metadata_dictlist.append(metadata_dict[cell_id])\n",
    "metadata_df = pd.DataFrame(metadata_dictlist)\n",
    "\n",
    "metadata_df['area'] = metadata_df['targeted_structure']\n",
    "\n",
    "def which_layer(depth):\n",
    "    if depth < 200:\n",
    "        return 'layer23'\n",
    "    if depth >= 200 and depth < 300:\n",
    "        return 'layer4'\n",
    "    if depth >= 300 and depth < 500:\n",
    "        return 'layer5'\n",
    "    if depth >= 500:\n",
    "        return 'layer6'\n",
    "    \n",
    "metadata_df['layer'] = metadata_df['imaging_depth'].apply(lambda x: which_layer(x))\n",
    "metadata_df = metadata_df.merge(cell_specimen_data, \n",
    "                                on = list(set.intersection(set(cell_specimen_data.columns), set(metadata_df.columns))))\n",
    "metadata_df['neural_site'] = metadata_df['area'] + '_' +  metadata_df['layer']\n",
    "\n",
    "output_file = os.path.join(output_dir, 'cell_metadata.csv')\n",
    "if not os.path.exists(output_file):\n",
    "    metadata_df.to_csv(output_file, index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_dflist_avg = []\n",
    "for cell_id in tqdm(response_dict_avg):\n",
    "    number_of_stimuli = len(response_dict_avg[cell_id])\n",
    "    incoming_df = pd.DataFrame({'cell_specimen_id': [cell_id] * number_of_stimuli, \n",
    "                                'stimulus': range(1,number_of_stimuli+1), \n",
    "                                'response': response_dict_avg[cell_id]})\n",
    "    response_dflist_avg.append(incoming_df)\n",
    "response_df_avg = pd.concat(response_dflist_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_data_combo_df = response_df_avg.merge(metadata_df, on='cell_specimen_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brain Observatory Responses by Site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes on Dictionary Structure\n",
    "* [Visual Area] > [Cre Line] > [Imaging Depth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './'\n",
    "data_saver_dir = 'response_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_data_from_experiments(all_trials=False):\n",
    "\n",
    "    response_dict = {}\n",
    "    with tqdm(experiments) as pbar:\n",
    "        for experiment in experiments:\n",
    "            if experiment['experiment_container_id'] in BAD_CONTAINER_IDS:\n",
    "                continue\n",
    "            experiment_id = experiment['id']\n",
    "            #print(\"Processing Experiment \", experiment_id)\n",
    "            pbar.set_description(\"Processing Experiment {}; {} Trials\"\n",
    "                                 .format(experiment_id, 'Averaging' if not all_trials else 'Appending All'))\n",
    "            \n",
    "\n",
    "            cre = experiment['cre_line'].split('-')[0]\n",
    "            depth = experiment['imaging_depth']\n",
    "            area = experiment['targeted_structure']\n",
    "\n",
    "            response_dict[area] = response_dict.get(area, {})\n",
    "            response_dict[area][cre] = response_dict[area].get(cre, {})\n",
    "            response_dict[area][cre][depth] = response_dict[area][cre].get(depth, [])\n",
    "\n",
    "            events = boc.get_ophys_experiment_events(experiment_id)\n",
    "            data = boc.get_ophys_experiment_data(experiment_id)\n",
    "            stim_table = data.get_stimulus_table('natural_scenes')\n",
    "            frames = np.unique(stim_table.frame)\n",
    "\n",
    "            if all_trials:\n",
    "                response_temp_list = []\n",
    "            if not all_trials: \n",
    "                response = np.zeros((len(frames), events.shape[0]))\n",
    "\n",
    "            for frame in frames:\n",
    "                frame_table = stim_table[stim_table.frame==frame]\n",
    "                trials = np.array([np.sum(events[:,row.start:row.end], axis=1) for i, row in frame_table.iterrows()])\n",
    "\n",
    "                if all_trials:\n",
    "                    response_temp_list.append(trials)\n",
    "                if not all_trials:\n",
    "                    response[frame] = np.mean(trials, axis=0)  \n",
    "\n",
    "            if all_trials:\n",
    "                frames_sort_index = np.argsort(frames)\n",
    "\n",
    "                response = [response_temp_list[i] for i in frames_sort_index]\n",
    "                trials = [frames[i]*np.ones(response_temp_list[frames[i]].shape[0]) for i in frames_sort_index]\n",
    "\n",
    "                # put grey screen (frame == -1) at the end of the array, should be sorted to first\n",
    "                grey = response.pop(0)\n",
    "                response.append(grey)  \n",
    "\n",
    "                grey_trial = trials.pop(0)\n",
    "                trials.append(grey_trial)\n",
    "                trials = np.hstack(trials)\n",
    "                response = np.vstack(response)  # [stim_table.shape[0], events.shape[0]]\n",
    "\n",
    "                # add list of trial ids here\n",
    "                response_dict[area][cre][depth].append((response, trials))\n",
    "\n",
    "            if not all_trials:\n",
    "                response_dict[area][cre][depth].append(response)\n",
    "            \n",
    "            pbar.update(1)\n",
    "\n",
    "    return response_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = os.path.join(output_dir, data_saver_dir, 'response_bytrial_bydepth.pkl')\n",
    "if os.path.exists(output_file):\n",
    "    response_dict_bytrial_bydepth = pickle.load(open(output_file, 'rb'))\n",
    "\n",
    "if not os.path.exists(output_file):\n",
    "    response_dict_bytrial_bydepth = get_response_data_from_experiments(all_trials=True)\n",
    "    with open(output_file, 'rb') as file:\n",
    "        pickle.dump(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = os.path.join(output_dir, data_saver_dir, 'response_average_bydepth.pkl')\n",
    "if os.path.exists(output_file):\n",
    "    response_dict = pickle.load(open(output_file, 'rb'))\n",
    "\n",
    "if not os.path.exists(output_file):\n",
    "    response_dict = get_response_data_from_experiments(all_trials=False)\n",
    "    \n",
    "    with open(output_file, 'wb') as file:\n",
    "        pickle.dump(response_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_dict_by_layer_from_depth(response_dict):\n",
    "    \n",
    "    def which_layer(depth):\n",
    "        if depth < 200:\n",
    "            return 'layer23'\n",
    "        if depth >= 200 and depth < 300:\n",
    "            return 'layer4'\n",
    "        if depth >= 300 and depth < 500:\n",
    "            return 'layer5'\n",
    "        if depth >= 500:\n",
    "            return 'layer6'\n",
    "        \n",
    "        \n",
    "    sample_area = next(iter(response_dict))\n",
    "    sample_creline = next(iter(response_dict[sample_area]))\n",
    "    sample_depth = next(iter(response_dict[sample_area][sample_creline]))\n",
    "    sample_response_dict = response_dict[sample_area][sample_creline][sample_depth][0]\n",
    "    \n",
    "    all_trials = type(sample_response_dict)==tuple     \n",
    "    if all_trials:\n",
    "        print(\"Condition: Trials Unconcatenated\")\n",
    "    if not all_trials:\n",
    "        print(\"Condition: Trials Averaged\")\n",
    "\n",
    "    trials_list = []\n",
    "    new_response_dict = {}\n",
    "    \n",
    "    for area in response_dict.keys():\n",
    "        new_response_dict[area] = {}\n",
    "        for cre in response_dict[area].keys():\n",
    "\n",
    "            depth_dict = {'layer23': [],\n",
    "                          'layer4': [],\n",
    "                          'layer5': [],\n",
    "                          'layer6': []}\n",
    "            \n",
    "            for depth in response_dict[area][cre].keys():\n",
    "            \n",
    "                if cre=='Nr5a1' or cre=='Scnn1a':\n",
    "                    depth_dict['layer4'] += response_dict[area][cre][depth]\n",
    "                else:\n",
    "                    depth_dict[which_layer(depth)] += response_dict[area][cre][depth]\n",
    "                \n",
    "                \n",
    "            new_response_dict[area][cre] = {}\n",
    "            \n",
    "            for layer in depth_dict.keys():\n",
    "                if len(depth_dict[layer])!=0: \n",
    "\n",
    "                    if all_trials:\n",
    "                        trials = [r[1] for r in depth_dict[layer]]\n",
    "                        trials = np.vstack(trials)\n",
    "                        trials_list.append(trials[0])\n",
    "                        depth_dict[layer] = np.hstack([r[0] for r in depth_dict[layer]])\n",
    "                        \n",
    "                    if not all_trials:\n",
    "                        depth_dict[layer] = np.hstack(depth_dict[layer])\n",
    "\n",
    "                    new_response_dict[area][cre][layer] = depth_dict[layer]\n",
    "\n",
    "    if all_trials:\n",
    "        trials = np.vstack(trials_list)\n",
    "        trials_list.append(trials[0])\n",
    "        \n",
    "        return new_response_dict\n",
    "    \n",
    "    if not all_trials:\n",
    "        return new_response_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_dict_bytrial_bysite = response_dict_by_layer_from_depth(response_dict_bytrial)\n",
    "\n",
    "output_file = os.path.join(output_dir, data_saver_dir, 'response_bytrial_bysite.pkl')\n",
    "if not os.path.exists(output_file):\n",
    "    with open(output_file, 'wb') as file:\n",
    "        pickle.dump(response_dict_bytrial, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_dict_bytrial_bysite = response_dict_by_layer_from_depth(response_dict)\n",
    "\n",
    "output_file = os.path.join(output_dir, data_saver_dir, 'response_average_bysite.pkl')\n",
    "if not os.path.exists(output_file):\n",
    "    with open(output_file, 'wb') as file:\n",
    "        pickle.dump(response_dict, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AllenSDK",
   "language": "python",
   "name": "allensdk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
